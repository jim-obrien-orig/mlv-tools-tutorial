{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train and test data set from 20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline step is based on the 02_Extract_dataset.ipynb Jupiter Notebook. It loads data downloaded in the previous step and splits it into a train or a test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "The following cell (the first code cell) contains a Docstring description of parameters of this step.\n",
    "\n",
    "**param** is used to declare parameters for the corresponding Python 3 script and command. \n",
    "\n",
    "\n",
    "| **param**  |  -- | impact  | \n",
    "| :---         |     :---      |          :--- |\n",
    "|python script | the method wrapping the following code accepts parameters | **subset:str, data_home:str, output_path:str**|\n",
    "|python command line  | it will accepts  | **--subset ['train'\\|'test'] --data-home [path] --output-path [path]**|\n",
    "    \n",
    "    \n",
    "**dvc-cmd** is used here because we want to run the python command twice. **dvc-run** allow to describe the whole DVC command when it is not generic.\n",
    "In this case it is possible (and strongly recommended) to use the variable **$MLV_PY_CMD_PATH** to designate the python command line path.\n",
    "\n",
    "\n",
    "To have a better understanding of those parameters, see the MLV-Tools [documentation](https://github.com/peopledoc/ml-versioning-tools) and have a look to the corresponding generated DVC command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "\"\"\"\n",
    ":param str subset: Subset of data to load\n",
    ":param str data_home: Path to parent directory to cache file\n",
    ":param str output_path: Path to output file\n",
    ":dvc-cmd: dvc run -f $MLV_DVC_META_FILENAME -o ./poc/data/data_train.csv -o ./poc/data/data_test.csv\n",
    "                -d ./poc/data/20news-bydate_py3.pkz\n",
    "       \"$MLV_PY_CMD_PATH --subset train\n",
    "            --data-home ./poc/data --output-path ./poc/data/data_train.csv &&\n",
    "        $MLV_PY_CMD_PATH --subset test\n",
    "            --data-home ./poc/data --output-path ./poc/data/data_test.csv\"\n",
    "\"\"\"\n",
    "# Value of parameters for this Jupyter Notebook only\n",
    "# the notebook is places in ./poc/pipeline/notebooks\n",
    "subset = 'train'\n",
    "data_home = '../../data/'\n",
    "# Output:\n",
    "output_path = '../../data/data_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset=subset,\n",
    "                                      data_home=data_home,\n",
    "                                      download_if_missing=False,\n",
    "                                      remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(newsgroups_train.data, columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['targetnames'] = df_train['target'].apply(lambda n: newsgroups_train.target_names[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
